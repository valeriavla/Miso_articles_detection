{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \" Data cleaning:\"\n",
        "---"
      ],
      "id": "1daad8e4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have our original dataset labeled_set.csv with 2 columns, \"text\" and \"label\", \"text\" column is the tweets we have gathered, and value 0 and 1 in \"label\" column represent the non misogynistic tweet and misogynistic tweet respetively. \n",
        "\n",
        "Right now the dataset is unuseble because there are way to many \"noises\" in our dataset, i.e. there are a lot of special characters, emojis, and website links in our text data, so we need to clean (remove) these \"noises\" before doing further analysis.\n",
        "\n",
        "Here are the data cleaning process step by step:\n",
        "\n",
        "- Import necessary libraries and packages\n"
      ],
      "id": "be9e07de"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk; \n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "import nltk\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer, PorterStemmer\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from textblob import TextBlob\n",
        "\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer"
      ],
      "id": "c44e744f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Load the original dataset\n"
      ],
      "id": "30da684e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tweets= pd.read_csv('../code/labeled_set.csv', encoding = \"ISO-8859-1\")\n",
        "tweets.head(10)"
      ],
      "id": "a522b4a3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}